{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import getpass\n",
        "# \n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using our Loan Data once again - this time the strutured data available through the CSV!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"./data/complaints.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Date received\", \n",
        "      \"Product\", \n",
        "      \"Sub-product\", \n",
        "      \"Issue\", \n",
        "      \"Sub-issue\", \n",
        "      \"Consumer complaint narrative\", \n",
        "      \"Company public response\", \n",
        "      \"Company\", \n",
        "      \"State\", \n",
        "      \"ZIP code\", \n",
        "      \"Tags\", \n",
        "      \"Consumer consent provided?\", \n",
        "      \"Submitted via\", \n",
        "      \"Date sent to company\", \n",
        "      \"Company response to consumer\", \n",
        "      \"Timely response?\", \n",
        "      \"Consumer disputed?\", \n",
        "      \"Complaint ID\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "loan_complaint_data = loader.load()\n",
        "\n",
        "for doc in loan_complaint_data:\n",
        "    doc.page_content = doc.metadata[\"Consumer complaint narrative\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': './data/complaints.csv', 'row': 0, 'Date received': '03/27/25', 'Product': 'Student loan', 'Sub-product': 'Federal student loan servicing', 'Issue': 'Dealing with your lender or servicer', 'Sub-issue': 'Trouble with how payments are being handled', 'Consumer complaint narrative': \"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\", 'Company public response': 'None', 'Company': 'Nelnet, Inc.', 'State': 'IL', 'ZIP code': '60030', 'Tags': 'None', 'Consumer consent provided?': 'Consent provided', 'Submitted via': 'Web', 'Date sent to company': '03/27/25', 'Company response to consumer': 'Closed with explanation', 'Timely response?': 'Yes', 'Consumer disputed?': 'N/A', 'Complaint ID': '12686613'}, page_content=\"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_complaint_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"LoanComplaints\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    loan_complaint_data,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"LoanComplaints\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retrieverQuestion\n",
        "\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "naive_retrieval_chain_with_scores = (\n",
        "    # Instead of using naive_retriever, use similarity_search_with_score directly\n",
        "    {\"context\": lambda x: vectorstore.similarity_search_with_score(x[\"question\"], k=10), \n",
        "     \"question\": itemgetter(\"question\")}\n",
        "    \n",
        "    # Process the (doc, score) tuples and extract scores\n",
        "    | RunnablePassthrough.assign(\n",
        "        context=lambda x: [doc for doc, score in x[\"context\"]],  # Extract just docs\n",
        "        scores=lambda x: [score for doc, score in x[\"context\"]]   # Extract just scores\n",
        "    )\n",
        "    \n",
        "    # Generate response and keep everything\n",
        "    | {\"response\": rag_prompt | chat_model, \n",
        "       \"context\": itemgetter(\"context\"),\n",
        "       \"scores\": itemgetter(\"scores\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Print the response text and scores\n",
        "def print_response_and_scores(result, title=\"Similarity Scores\", print_context=False):\n",
        "    print(result[\"response\"].content)\n",
        "    scores = result[\"scores\"]\n",
        "    print(f\"\\n{title}\")\n",
        "    print(\"-\" * len(title))\n",
        "    for i, score in enumerate(scores, 1):\n",
        "        print(f\"Doc {i:2d} score: {score:.4f}\")\n",
        "\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"Average score: {np.mean(scores):.4f}\")\n",
        "    print(f\"Best:    {max(scores):.4f}\")\n",
        "    print(f\"Worst:   {min(scores):.4f}\")\n",
        "    if print_context:\n",
        "        print(\"\\nContext:\")\n",
        "        for doc in result[\"context\"]:\n",
        "            print(f\"- {doc.page_content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = naive_retrieval_chain_with_scores.invoke({\"question\": \"Did any complaints not get handled in a timely manner?\"})\n",
        "print_response_and_scores(result, title=\"naive_retrieval_chain_with_scores\", print_context=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, yes, some complaints did not get handled in a timely manner. Specifically, at least one complaint (Complaint ID: 12709087 submitted to MOHELA) was marked as \"No\" under the \"Timely response?\" column, indicating it was not responded to in a timely way. The other complaints, such as those to Maximus Federal Services and EdFinancial Services, were marked as \"Yes,\" suggesting they were handled within the expected timeframe.\n",
            "\n",
            "naive_retrieval_chain_with_scores\n",
            "---------------------------------\n",
            "Doc  1 score: 0.5304\n",
            "Doc  2 score: 0.4860\n",
            "Doc  3 score: 0.4820\n",
            "Doc  4 score: 0.4675\n",
            "Doc  5 score: 0.4597\n",
            "Doc  6 score: 0.4590\n",
            "Doc  7 score: 0.4580\n",
            "Doc  8 score: 0.4558\n",
            "Doc  9 score: 0.4536\n",
            "Doc 10 score: 0.4500\n",
            "\n",
            "Summary:\n",
            "Average score: 0.4702\n",
            "Best:    0.5304\n",
            "Worst:   0.4500\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print_response_and_scores(result, title=\"naive_retrieval_chain_with_scores\", print_context=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, there are 5 complaints marked as \"Timely response?\" with a \"Yes\" in the field. None of these complaints have a non-positive connotation in the \"Timely response\" field; they all indicate a positive or satisfactory response status. Since the question specifically asks about complaints with a non-positive connotation in the \"Timely response\" field, and all noted responses are positive (\"Yes\"), the answer is:\\n\\nZero complaints with a \"Timely response?\" marked as \"Yes\" had a non-positive connotation in the \"Timely response\" field.'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "naive_retrieval_chain_with_scores.invoke({\"question\" : 'How many Complaints marked as \"Timely response?\" had a non-positive conotation in the Timeliy response field?'})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most common issues with loans, based on the complaints provided, include:\n",
            "\n",
            "- Errors and discrepancies in loan balances and account information\n",
            "- Problems with repayment and payment application, such as difficulty applying extra funds or payments being misapplied\n",
            "- Issues related to loan transfer and lack of proper notification\n",
            "- Unfair or confusing interest rate increases and loan terms\n",
            "- Problems with loan reporting and credit report inaccuracies\n",
            "- Challenges with loan forgiveness, cancellation, or discharge\n",
            "- Mishandling of loan data and violations of privacy laws\n",
            "\n",
            "Overall, issues around mismanagement, inaccuracies, and poor communication between lenders/servicers and borrowers appear to be most prevalent.\n",
            "\n",
            "naive_retrieval_chain_with_scores\n",
            "---------------------------------\n",
            "Doc  1 score: 0.5133\n",
            "Doc  2 score: 0.4949\n",
            "Doc  3 score: 0.4940\n",
            "Doc  4 score: 0.4930\n",
            "Doc  5 score: 0.4896\n",
            "Doc  6 score: 0.4889\n",
            "Doc  7 score: 0.4833\n",
            "Doc  8 score: 0.4796\n",
            "Doc  9 score: 0.4787\n",
            "Doc 10 score: 0.4748\n",
            "\n",
            "Summary:\n",
            "Average score: 0.4890\n",
            "Best:    0.5133\n",
            "Worst:   0.4748\n"
          ]
        }
      ],
      "source": [
        "result = naive_retrieval_chain_with_scores.invoke({\"question\": \"What is the most common issue with loans?\"})\n",
        "print_response_and_scores(result, title=\"naive_retrieval_chain_with_scores\", print_context=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the complaints data, appears to be problems related to the handling and management of student loans, including errors in loan balances, misapplied payments, wrongful denials of payment plans, and issues stemming from loan transfers and information inaccuracies. Many complaints also involve the inability to properly apply payments, inaccurate reporting of account status, and issues with loan balances growing despite payments made.\\n\\nIn summary, the most common issues are:\\n- Errors and inaccuracies in loan balances and reporting\\n- Difficulties in managing payments and payment application\\n- Problems arising from loan transfer or mismanaged accounts\\n- Disputes over loan information and account status\\n\\nIf you are experiencing a specific issue, it is often related to mismanagement or inaccuracies in loan data and handling.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, yes, some complaints did not get handled in a timely manner. Specifically, the complaint with the ID 12709087 regarding issues with a graduated loan application submitted on 03/28/25 was marked as \"Timely response?\": No, indicating it was not handled promptly. Additionally, multiple complaints highlight delays and lack of responses over extended periods, such as over a year for certain account review requests and unresolved disputes.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided data, yes, there were complaints that did not get handled in a timely manner. Specifically, the complaint with Complaint ID 12709087, received on 03/28/25, was marked as \"Timely response?\": \"No,\" indicating it was not handled in a timely manner. The complainant reported that despite multiple follow-ups, their issue remained unresolved and no response had been received for an extended period.\n",
            "\n",
            "naive_retrieval_chain_with_scores\n",
            "---------------------------------\n",
            "Doc  1 score: 0.5304\n",
            "Doc  2 score: 0.4860\n",
            "Doc  3 score: 0.4820\n",
            "Doc  4 score: 0.4675\n",
            "Doc  5 score: 0.4597\n",
            "Doc  6 score: 0.4590\n",
            "Doc  7 score: 0.4580\n",
            "Doc  8 score: 0.4558\n",
            "Doc  9 score: 0.4536\n",
            "Doc 10 score: 0.4500\n",
            "\n",
            "Summary:\n",
            "Average score: 0.4702\n",
            "Best:    0.5304\n",
            "Worst:   0.4500\n"
          ]
        }
      ],
      "source": [
        "result = naive_retrieval_chain_with_scores.invoke({\"question\": \"Did any complaints not get handled in a timely manner?\"})\n",
        "print_response_and_scores(result, title=\"naive_retrieval_chain_with_scores\", print_context=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided data, there are 5 complaints that were marked as \"Timely response?\" with a response that is either negative, non-committal, or indicates no resolution (i.e., responses such as \"Closed with explanation\" or \"Company has responded and chooses not to provide a public response\"). These complaints show that even though the response was marked as \"Yes\" for timeliness, the actual content or context indicates unresolved issues or inadequate resolution.\n",
            "\n",
            "To precisely answer the question: \n",
            "\n",
            "**Number of complaints marked as \"Timely response?\" with a negative or undefined response in the \"Timely Response\" column: 5.**\n",
            "\n",
            "naive_retrieval_chain_with_scores\n",
            "---------------------------------\n",
            "Doc  1 score: 0.4394\n",
            "Doc  2 score: 0.4341\n",
            "Doc  3 score: 0.4299\n",
            "Doc  4 score: 0.4273\n",
            "Doc  5 score: 0.4198\n",
            "Doc  6 score: 0.4188\n",
            "Doc  7 score: 0.4152\n",
            "Doc  8 score: 0.4152\n",
            "Doc  9 score: 0.4127\n",
            "Doc 10 score: 0.4116\n",
            "\n",
            "Summary:\n",
            "Average score: 0.4224\n",
            "Best:    0.4394\n",
            "Worst:   0.4116\n"
          ]
        }
      ],
      "source": [
        "\n",
        "result=naive_retrieval_chain_with_scores.invoke({\"question\" : 'How many Complaints marked as \"Timely response?\" had a negative  or undifined response in the Timely Response column?'})\n",
        "print_response_and_scores(result, title=\"naive_retrieval_chain_with_scores\", print_context=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for several reasons, including:\\n\\n1. **Accumulation of interest and inability to afford payments:** Many borrowers found that lowering monthly payments led to continued interest accumulation, which increased the total debt and extended the payoff period, making repayment more difficult overall.\\n\\n2. **Financial hardships and stagnant wages:** Borrowers often faced financial hardships due to economic conditions, stagnant wages, or unexpected expenses, which made it impossible to keep up with payments without sacrificing basic necessities.\\n\\n3. **Lack of clear or adequate communication:** Some borrowers were not properly informed about their loan status, changes in servicers, or the resumption of payments after forbearance or deferment periods. This lack of information caused missed payments and credit issues.\\n\\n4. **Administrative errors and mismanagement by loan servicers:** Transfer of loan accounts without proper notification, incorrect reporting of payments or delinquencies, and difficulties in applying payments correctly contributed to failed repayment attempts.\\n\\n5. **High interest rates and long-term forbearance:** Years of high interest rates, long-term forbearance, and mismanagement led to increased balances despite ongoing payments, making it hard for borrowers to pay off the loans.\\n\\n6. **Limited access to forgiveness or relief programs:** Many borrowers did not qualify for loan forgiveness programs or repayment plans that could have eased their repayment burden, leading to continued struggle.\\n\\n7. **Unfavorable repayment terms and predatory practices:** Some borrowers experienced predatory practices such as being unable to target extra payments toward principal or being steered into payment plans that favor the servicerâ€™s financial interests.\\n\\nThese combined factors often resulted in borrowers being unable to meet their repayment obligations, leading to unpaid loans and adverse impacts on their credit and financial stability.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to compare retrievers with scores\n",
        "def compare_retrievers_with_scores(question, retrievers_dict):\n",
        "    \"\"\"\n",
        "    Compare multiple retrievers and their similarity scores\n",
        "    \n",
        "    Args:\n",
        "        question: The query to test\n",
        "        retrievers_dict: Dictionary of {name: retriever_function} pairs\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with results for each retriever\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for name, retriever_func in retrievers_dict.items():\n",
        "        try:\n",
        "            # Get documents with scores\n",
        "            docs = retriever_func(question)\n",
        "            scores = [doc.metadata.get(\"score\", 0.0) for doc in docs if hasattr(doc, 'metadata')]\n",
        "            \n",
        "            results[name] = {\n",
        "                \"scores\": scores,\n",
        "                \"avg_score\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_score\": max(scores) if scores else 0,\n",
        "                \"min_score\": min(scores) if scores else 0,\n",
        "                \"num_docs\": len(docs)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            results[name] = {\"error\": str(e)}\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Example usage for comparing different retrievers\n",
        "# You can add more custom retrievers here as you implement them\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3331941400.py, line 9)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"BM25 retriever that adds rank-based scores to document metadata\"\"\"\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Example: Create a BM25 retriever with scores for comparison\n",
        "# Note: BM25 retrievers don't have built-in similarity_search_with_score, \n",
        "# so we'll simulate scores based on rank position\n",
        "\"\"\"\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "@chain\n",
        "def bm25_retriever_with_scores(query: str) -> List[Document]:\n",
        "    #BM25 retriever that adds rank-based scores to document metadata\n",
        "    docs = bm25_retriever.invoke(query)\n",
        "    \n",
        "    # BM25 doesn't provide similarity scores like vector search,\n",
        "    # so we'll use rank-based scoring (higher rank = lower score)\n",
        "    for i, doc in enumerate(docs):\n",
        "        # Rank-based score: starts at 1.0 and decreases by 0.1 for each rank\n",
        "        rank_score = max(0.1, 1.0 - (i * 0.1))\n",
        "        doc.metadata[\"score\"] = rank_score\n",
        "        doc.metadata[\"rank\"] = i + 1\n",
        "    \n",
        "    return docs\n",
        "\n",
        "# Test comparison between naive (vector) and BM25 retrievers\n",
        "test_question = \"Did any complaints not get handled in a timely manner?\"\n",
        "\n",
        "retriever_comparison = compare_retrievers_with_scores(\n",
        "    test_question,\n",
        "    {\n",
        "        \"Naive (Vector)\": naive_retriever_with_scores,\n",
        "        \"BM25 (Rank-based)\": bm25_retriever_with_scores\n",
        "    }\n",
        ")\n",
        "\n",
        "def print_retriever_comparison_results(retriever_comparison):\n",
        "    print(\"Retriever Comparison Results:\")from langchain_core.runnables import chainfrom langchain_core.runnables import chain\n",
        "    print(\"=\"*40)\n",
        "    for name, metrics in retriever_comparison.items():\n",
        "        if \"error\" not in metrics:\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  Average Score: {metrics['avg_score']:.4f}\")\n",
        "            print(f\"  Max Score: {metrics['max_score']:.4f}\")\n",
        "            print(f\"  Min Score: {metrics['min_score']:.4f}\")\n",
        "            print(f\"  Documents Retrieved: {metrics['num_docs']}\")\n",
        "        else:\n",
        "            print(f\"\\n{name}: Error - {metrics['error']}\")\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# General function to create retrieval chains with scores\n",
        "def create_retrieval_chain_with_scores(retriever_func, chain_name=\"\"):\n",
        "    \"\"\"\n",
        "    Create a retrieval chain that includes similarity scores\n",
        "    \n",
        "    Args:\n",
        "        retriever_func: A retriever function that returns documents with scores in metadata\n",
        "        chain_name: Optional name for the chain (for debugging)\n",
        "    \n",
        "    Returns:\n",
        "        A LangChain LCEL chain that returns response, context, and scores\n",
        "    \n",
        "    def extract_scores_from_context(context):\n",
        "        return [doc.metadata.get(\"score\", 0.0) for doc in context]\n",
        "    \n",
        "    chain = (\n",
        "        {\"context\": itemgetter(\"question\") | retriever_func, \"question\": itemgetter(\"question\")}\n",
        "        | RunnablePassthrough.assign(\n",
        "            context=itemgetter(\"context\"),\n",
        "            scores=lambda x: extract_scores_from_context(x[\"context\"])\n",
        "        )\n",
        "        | {\n",
        "            \"response\": rag_prompt | chat_model, \n",
        "            \"context\": itemgetter(\"context\"),\n",
        "            \"scores\": itemgetter(\"scores\"),\n",
        "            \"question\": itemgetter(\"question\"),\n",
        "            \"chain_name\": lambda x: chain_name\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    return chain\n",
        "\n",
        "# Create chains for different retrievers\n",
        "# naive_chain_with_scores = create_retrieval_chain_with_scores(naive_retrieval_chain_with_scores, \"Naive Vector\")\n",
        "bm25_chain_with_scores = create_retrieval_chain_with_scores(bm25_retriever_with_scores, \"BM25\")\n",
        "\n",
        "print(\"Created retrieval chains with similarity scores!\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive chain comparison with scores\n",
        "def compare_chains_with_scores(question, chains_dict):\n",
        "    \"\"\"\n",
        "    Compare multiple retrieval chains and their performance\n",
        "    \n",
        "    Args:\n",
        "        question: The query to test\n",
        "        chains_dict: Dictionary of {name: chain} pairs\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with results for each chain\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    print(f\"Testing Question: '{question}'\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for chain_name, chain in chains_dict.items():\n",
        "        print(f\"\\n{chain_name} Results:\")\n",
        "        print(\"-\" * 30)\n",
        "        \n",
        "        try:\n",
        "            result = chain.invoke({\"question\": question})\n",
        "            scores = result[\"scores\"]\n",
        "            \n",
        "            print(f\"Response: {result['response'].content[:200]}...\")\n",
        "            print(f\"\\nScores Summary:\")\n",
        "            print(f\"  Average: {sum(scores)/len(scores):.4f}\")\n",
        "            print(f\"  Max: {max(scores):.4f}\")\n",
        "            print(f\"  Min: {min(scores):.4f}\")\n",
        "            print(f\"  Std Dev: {(sum([(s - sum(scores)/len(scores))**2 for s in scores])/len(scores))**0.5:.4f}\")\n",
        "            \n",
        "            # Store results for analysis\n",
        "            results[chain_name] = {\n",
        "                \"response\": result['response'].content,\n",
        "                \"scores\": scores,\n",
        "                \"avg_score\": sum(scores)/len(scores),\n",
        "                \"max_score\": max(scores),\n",
        "                \"min_score\": min(scores),\n",
        "                \"num_docs\": len(scores)\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            results[chain_name] = {\"error\": str(e)}\n",
        "    \n",
        "    return results\n",
        "\n",
        "\"\"\"\n",
        "Advanced_Retrieval_with_LangChain_Assignment.ipynb\n",
        "# Test both chains\n",
        "test_question = \"Why did people fail to pay back their loans?\"\n",
        "\n",
        "chain_comparison = compare_chains_with_scores(\n",
        "    test_question,\n",
        "    {\n",
        "        \"Naive Vector Chain\": naive_chain_with_scores,\n",
        "        \"BM25 Chain\": bm25_chain_with_scores\n",
        "    }\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most common issues with loans, based on the complaints provided, include:\n",
            "\n",
            "- Errors and discrepancies in loan balances and account information\n",
            "- Problems with repayment and payment application, such as difficulty applying extra funds or payments being misapplied\n",
            "- Issues related to loan transfer and lack of proper notification\n",
            "- Unfair or confusing interest rate increases and loan terms\n",
            "- Problems with loan reporting and credit report inaccuracies\n",
            "- Challenges with loan forgiveness, cancellation, or discharge\n",
            "- Mishandling of loan data and violations of privacy laws\n",
            "\n",
            "Overall, issues around mismanagement, inaccuracies, and poor communication between lenders/servicers and borrowers appear to be most prevalent.\n",
            "\n",
            "naive_retrieval_chain_with_scores\n",
            "---------------------------------\n",
            "Doc  1 score: 0.5133\n",
            "Doc  2 score: 0.4949\n",
            "Doc  3 score: 0.4940\n",
            "Doc  4 score: 0.4930\n",
            "Doc  5 score: 0.4896\n",
            "Doc  6 score: 0.4889\n",
            "Doc  7 score: 0.4833\n",
            "Doc  8 score: 0.4796\n",
            "Doc  9 score: 0.4787\n",
            "Doc 10 score: 0.4748\n",
            "\n",
            "Summary:\n",
            "Average score: 0.4890\n",
            "Best:    0.5133\n",
            "Worst:   0.4748\n"
          ]
        }
      ],
      "source": [
        "result = naive_retrieval_chain_with_scores.invoke({\"question\": \"What is the most common issue with loans?\"})\n",
        "print_response_and_scores(result, title=\"naive_retrieval_chain_with_scores\", print_context=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(loan_complaint_data, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, it appears that the most common issues with loans, particularly federal student loans, involve problems with loan servicing and miscommunication or misinformation from lenders or servicers. Specific issues include:\\n\\n- Dealing with lenders or servicers who do not provide clear or accurate information.\\n- Problems with applying payments correctly, especially applying additional funds to principal or paying off loans faster.\\n- Difficulty in accessing or understanding loan information, such as balances, interest, or repayment plans.\\n- Disputes over fees, interest calculations, and the validity of the schools attended.\\n\\nOverall, a prevalent theme is frustration with loan servicers handling payments, providing misinformation, or failing to offer transparent and accurate assistance. \\n\\nSo, the most common issue seems to be related to **poor communication and handling of loan payments and information by the loan servicers**.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, several complaints were responded to in a timely manner, as indicated by the \"Timely response?\" field being \"Yes\" for each complaint. There is no record of any complaints that were not handled in a timely manner.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, there are four complaints marked as \"Timely response?\" with a \"Yes\" in the field. Out of these four, three have consumer complaint narratives that express dissatisfaction, frustration, or negative sentiments, which can be interpreted as a non-positive connotation. These complaints are:\\n\\n1. Complaint with ID 13117781 (from row 480) - The narrative expresses frustration about loan forgiveness and the impact of COVID-19 on career prospects, indicating a negative or distressed connotation.\\n2. Complaint with ID 12783455 (from row 508) - The narrative describes poor business practices, unhelpful responses, and feelings of frustration and lack of support, clearly non-positive.\\n3. Complaint with ID 13001900 (from row 86) - The narrative discusses significant and devastating drops in credit scores, systemic issues, and feelings of being overwhelmed and betrayed, indicating a negative connotation.\\n\\nThe remaining complaint (ID 12933454, from row 61) has a neutral or more procedural tone, focusing on requesting information without expressing overt dissatisfaction.\\n\\n**Therefore, the number of \"Timely response?\" complaints that had a non-positive connotation in their narratives is 3.**'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "bm25_retrieval_chain.invoke({\"question\" : 'How many Complaints marked as \"Timely response?\" had a non-positive conotation in the Timeliy response field?'})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, several complaints were responded to in a timely manner, as indicated by the \"Timely response?\" field being \"Yes\" for each complaint. There is no record of any complaints that were not handled in a timely manner.'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for various reasons, including difficulties with payment plans, miscommunication or lack of communication from the loan servicers, and issues with the handling of their accounts. Some specific reasons seen in the complaints include being steered into wrong types of forbearances, servicers not responding or providing timely assistance, unnotified transfers of loans to new companies without proper contact or consent, billing errors leading to wrongful charges or overdue statuses, and technical issues such as payments being reversed or not processed correctly despite available funds. Additionally, some borrowers experienced negative impacts on their credit scores due to lack of transparency or failure to notify them about changes or overdue statuses.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse, if only we had a way to test this (SPOILERS: We do, the second half of the notebook will cover this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #1:\n",
        "\n",
        "Give an example query where BM25 is better than embeddings and justify your answer.\n",
        "\n",
        "#### âœ… Answer #1:\n",
        "\n",
        "In the present case we see that the naive_embeddings_retriever retrieved more information than the BM25:   \n",
        "Embeddings:  \n",
        "\n",
        ">*some complaints did not get handled in a timely manner. Specifically, the complaint with the ID 12709087 regarding issues with a graduated loan application submitted on 03/28/25 was marked as \"Timely response?\": No, indicating it was not handled promptly. Additionally, multiple complaints highlight delays and lack of responses over extended periods, such as over a year for certain account review requests and unresolved disputes.'*\n",
        "\n",
        "BM25 (partial incomplete information)\n",
        "\n",
        ">*Based on the provided information, several complaints were responded to in a timely manner, as indicated by the \"Timely response?\" field being \"Yes\" for each complaint. There is no record of any complaints that were not handled in a timely manner.*\n",
        "\n",
        "BM25 is a RANKING algorithm within the Probabilistic Relevance Framework, which ranks documents according to their relevance to the user queries. It is focused on relevance (provides a relevance score)  rather than semantics. It is also looking for how often query terms (term frequency) appear in the documents. It also takes into account the length of the document, and the inverse document frequency.  \n",
        "\n",
        "For example the BM25 Using this querry:\n",
        "\n",
        ">*bm25_retrieval_chain.invoke({\"question\" : 'How many Complaints marked as \"Timely response?\" had a non-positive conotation in the Timeliy response field?'})[\"response\"].content*\n",
        "\n",
        "The response is:  \n",
        "\n",
        ">*'Based on the provided data, there are four complaints marked as \"Timely response?\" with a \"Yes\" in the field. Out of these four, three have consumer complaint narratives that express dissatisfaction, frustration, or negative sentiments, which can be interpreted as a non-positive connotation. These complaints are:\\n\\n1. Complaint with ID 13117781 (from row 480) - The narrative expresses frustration about loan forgiveness and the impact of COVID-19 on career prospects, indicating a negative or distressed connotation.\\n2. Complaint with ID 12783455 (from row 508) - The narrative describes poor business practices, unhelpful responses, and feelings of frustration and lack of support, clearly non-positive.\\n3. Complaint with ID 13001900 (from row 86) - The narrative discusses significant and devastating drops in credit scores, systemic issues, and feelings of being overwhelmed and betrayed, indicating a negative connotation.\\n\\nThe remaining complaint (ID 12933454, from row 61) has a neutral or more procedural tone, focusing on requesting information without expressing overt dissatisfaction.\\n\\n**Therefore, the number of \"Timely response?\" complaints that had a non-positive connotation in their narratives is 3.**'*\n",
        "\n",
        "Providing exact keywords in the query, the BM25 not only provided correct results, but it also gave the count.  \n",
        "\n",
        "whereas the naive_retrieval_chain:  \n",
        ">*result=naive_retrieval_chain_with_scores.invoke({\"question\" : 'How many Complaints marked as \"Timely response?\" had a non-positive conotation in the Timeliy response field?'})[\"response\"].content*\n",
        "\n",
        "Gave this incorrect response:  \n",
        "\n",
        ">*'Based on the provided data, there are 5 complaints marked as \"Timely response?\" with a \"Yes\" in the field. None of these complaints have a non-positive connotation in the \"Timely response\" field; they all indicate a positive or satisfactory response status. Since the question specifically asks about complaints with a non-positive connotation in the \"Timely response\" field, and all noted responses are positive (\"Yes\"), the answer is:\\n\\nZero complaints with a \"Timely response?\" marked as \"Yes\" had a non-positive connotation in the \"Timely response\" field.'*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, the most common issue with loans appears to be problems related to dealing with lenders or servicers, specifically including errors in loan balances, misapplied payments, wrongful denials of payment plans, incorrect or confusing information, and mishandling of loan data. Many complaints also involve lack of communication, incorrect information, unauthorized transfers, and privacy violations.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, there are indications that some complaints did not get handled in a timely manner. For example, one complaint regarding federal student loan servicing issues has been open since an unspecified date (\"since XXXX\") and still has not been resolved after nearly 18 months, despite the company response indicating the response was \"timely.\" Additionally, multiple complaints mention waiting over a year for responses or resolutions, which suggests delays in handling these complaints. Therefore, yes, some complaints were not handled in a timely manner.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans primarily due to a combination of factors such as a lack of proper information about their loans and repayment requirements, administrative issues, and financial hardship. Specifically, some borrowers were not aware that they needed to repay student loans or were never informed about the repayment process, resulting in unawareness or confusion. Administrative problems, such as transfers of loans without notification, difficulties accessing online accounts, or incorrect account information, further complicated repayment efforts. Additionally, borrowers faced financial challenges because the options availableâ€”like forbearance or defermentâ€”often led to accruing interest, which increased the total debt over time and made it more difficult to pay off the loans. The accumulation of interest, combined with stagnant wages and unexpected financial burdens, contributed to many borrowers being unable to repay their loans fully.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the complaints provided, appears to be problems with how student loan servicers handle payments, including errors in loan balances, misapplied payments, refusal or difficulty in applying extra payments to principal, and extensive issues with loan documentation and validation. Many complaints also highlight poor communication, incorrect or inconsistent loan information, unauthorized transfers, and disputes over interest calculations and loan totals.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, based on the provided complaints, some complaints were not handled in a timely manner. For example, one complaint (Complaint ID: 12709087) received by MOHELA was marked as \"Timely response?\": No, indicating it was not handled promptly. Additionally, multiple complaints mention delays of over a year, months, or weeks without resolution, confirming that certain issues did not get addressed in a timely manner.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans primarily due to a combination of systemic issues, lack of clear information, and financial hardships. Specifically, many borrowers were not adequately informed about how forbearance and deferment options work, particularly that interest would continue to accrue and compound, making the total debt grow faster than expected. Some were steered into long-term forbearances or consolidations without being informed about alternative options like income-driven repayment or loan rehabilitation, which could have helped manage or reduce their debt. \\n\\nAdditionally, borrowers faced challenges like sudden transfers between loan servicers, incorrect reporting of account statuses, or being kept in forbearance without proper communication. Many have experienced unaffordable payment demands, increased loan balances due to interest capitalization, and a lack of support or guidance from loan servicers, all of which contribute to their inability to pay back their loans. External hardships such as unemployment, medical issues, homelessness, and economic downturns further hinder their ability to repay.\\n\\nOverall, the failure to pay back loans is largely linked to systemic mismanagement, inadequate borrower education, and personal financial difficulties, rather than irresponsibility.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #2:\n",
        "\n",
        "Explain how generating multiple reformulations of a user query can improve recall.\n",
        "\n",
        "\n",
        "#### âœ… Answer #2:\n",
        "\n",
        "$\\text{Recall} = \\Large{\\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Negatives}}}$\n",
        "\n",
        "Therefore the more the datapoints (i.e. context) the better the recall gets, especially if the false negatives decrease. As we saw, once we added more querries, the model with just the naive retriecer, was able to identify:   \n",
        ">\"based on the provided complaints, some complaints were not handled in a timely manner.For example, one complaint (Complaint ID: 12709087) received by MOHELA was marked as \"Timely response?\": No, indicating it was not handled promptly. Additionally, multiple complaints mention delays of over a year, months, or weeks without resolution, confirming that certain issues did not get addressed in a timely manner.\"  \n",
        "\n",
        "Whereas before, the naive retriever with just one query gave:  \n",
        ">\"Based on the provided information, several complaints were responded to in a timely manner, as indicated by the \"Timely response?\" field being \"Yes\" for each complaint. There is no record of any complaints that were not handled in a timely manner\"\n",
        "\n",
        "Which is *False Negative\", and thus decreases Recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = loan_complaint_data\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=750)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = QdrantVectorStore(\n",
        "    collection_name=\"full_documents\", \n",
        "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), \n",
        "    client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the complaints provided, appears to be related to errors and misconduct in federal student loan servicing. Specific recurring problems include incorrect information on credit reports, misapplication of payments, wrongful denials of payment plans, discrepancies in loan balances and interest rates, and issues with collection and verification of debts.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, it appears that several complaints were not handled in a timely manner. Specifically, the complaints related to the student loan issues with MOHELA (Complaint IDs 12709087 and 12935889) indicate that the responses were \"No\" in the \"Timely response?\" field, meaning they were not handled promptly. Additionally, the complaint about the dispute settlement with Nelnet (Complaint ID 13205525) was responded to within the expected timeframe (\"Yes\" in \"Timely response?\"). \\n\\nTherefore, yes, some complaintsâ€”particularly those regarding MOHELAâ€”did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for various reasons, including:\\n\\n1. Lack of proper communication or notification from loan servicers about payment obligations, as indicated by complaints about not being notified when payments were due or about changes in loan ownership.\\n2. Financial hardship or severe economic difficulties that made it impossible to make timely payments, such as unemployment or inability to find employment in their field.\\n3. Misrepresentation or lack of transparency from educational institutions and loan providers regarding the long-term financial consequences, job prospects after graduation, and the sustainability of the schoolâ€™s operations.\\n4. Relying on deferment and forbearance options that increased interest and debt over time.\\n5. Disputes over the legitimacy or ownership of the debt, including issues related to the legal verification of loans and deceptive practices by collection agencies.\\n6. Personal health issues or other personal circumstances that hindered ability to make payments.\\n\\nIn summary, failure to repay loans often resulted from a combination of financial hardship, lack of clear communication, and sometimes the mismanagement or misrepresentation by educational and loan servicing entities.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided data, appears to be dealing with the loan servicer or lender, including errors in loan balances, misapplied payments, wrongful denials of payment plans, and problems with how payments are being handled. Several complaints highlight issues such as receiving bad information about loans, inability to properly apply payments to principal, inaccurate reporting of delinquency, and mishandling of loan transfers or consolidations. \\n\\nIn summary, a predominant and recurring problem is the mismanagement and poor communication from loan servicers, which leads to misapplied payments, incorrect account information, and difficulties in resolving repayment issues.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, yes, there are several instances indicating complaints not handled in a timely manner. For example:\\n\\n- One complaint (#12935889) about Mohela was marked as \"Timely response?\": No.\\n- Another (#12744910) regarding inaccuracies in reporting and an ongoing dispute was \"Timely response?\": Yes, but the complaint was about inaccurate reporting and delays in correction, suggesting the issue persisted over time.\\n- Multiple complaints (#12739706, #13062402, #13126709, #13127090, and others) mention delays, extended wait times, or responses that were not addressed promptly, with some even explicitly stating they did not receive responses within expected timeframes.\\n- There are cases where the response was \"Closed with explanation\" but the delays or unresolved issues strongly imply they were not handled promptly or adequately.\\n\\nOverall, the evidence suggests that at least some complaints were not handled in a timely manner, as indicated directly by the response statuses and detailed descriptions of delays.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for several reasons, often related to mismanagement, misinformation, and systemic issues. Based on the provided complaints, common reasons include:\\n\\n1. **Lack of Notification and Communication:** Many borrowers were not properly notified about loan transfers, due dates, or repayment start dates, leading to unintentional delinquency and missed payments.\\n\\n2. **Misleading or Incomplete Information:** Borrowers reported receiving incorrect or misleading information about their loan balances, repayment obligations, or eligibility for programs like income-driven repayment or forgiveness, which caused confusion and unintended default.\\n\\n3. **System Errors and Technical Difficulties:** Issues such as online portal lockouts, incorrect account statuses, and errors in reporting contributed to borrowers not making payments or being marked delinquent improperly.\\n\\n4. **Inadequate Support and Assistance:** Borrowers often found customer service unhelpful, unresponsive, or dismissive, preventing them from arranging manageable payment plans or resolving discrepancies.\\n\\n5. **Financial Hardship and Economic Factors:** Some borrowers experienced severe financial difficulties, unemployment, or health issues that made repayment impossible despite intentions to pay.\\n\\n6. **Systemic and Administrative Failures:** Transitions between servicers, erroneous reporting to credit bureaus, and failure to follow regulations led to credit damage and further complications in repayment.\\n\\nIn summary, failures to pay back loans often stemmed from a combination of administrative mismanagement, inadequate communication, lack of clarity about repayment options, and financial hardships.'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(loan_complaint_data[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Loan_Complaint_Data_Semantic_Chunks\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, the most common issues with loans appear to be related to difficulties in communication and account management, such as:\\n\\n- Struggling to repay loans due to errors or issues with payment plans.\\n- Problems with loan reporting, including incorrect or improper reporting of account status or default.\\n- Difficulties in obtaining clear information about loan balances, loan servicer changes, or payment amounts.\\n- Issues with loan servicing companies failing to respond appropriately or failing to verify or process applications.\\n- Unauthorized or illegal reporting and collection practices, including violations of privacy laws.\\n\\nWhile these are specific to student loans in the context provided, a recurring theme is that many complaints involve mismanagement, lack of transparency, or errors in the handling of loans and related information. \\n\\nTherefore, a common underlying issue with loans, especially highlighted here, is **mismanagement or errors in servicing, reporting, or communication that cause confusion, financial hardship, or violations of legal protections.**'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, it appears that many complaints were responded to in a timely manner, with responses marked as \\'Yes\\' under the \\'Timely response?\\' field. Notably, several complaints state \"Closed with explanation,\" indicating that they were addressed within the required time frame. \\n\\nHowever, there is at least one complaint regarding a lack of response or handlingâ€”specifically, the complaint about Nelnet (row 17). The consumer\\'s narrative details multiple issues with lack of responses and conduct that suggests their complaint was not handled promptly or satisfactorily.\\n\\nIn summary:\\n\\n- Multiple complaints confirm responses were handled in a timely manner.\\n- One complaint (about Nelnet\\'s failure to respond to Certified Mail and ongoing misconduct) indicates that the complaint was not properly handled or responded to, suggesting that some complaints did not get handled in a timely manner.\\n\\nTherefore, yes, some complaints did not get handled in a timely manner, specifically the complaint involving Nelnet\\'s lack of response to legal and misconduct issues.'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans for various reasons, including issues such as difficulties dealing with their loan servicers, miscommunications or inadequate information about their loan status, problems with payment processing, and disputes over the legitimacy or accuracy of their loan details. Some specific reasons noted in the complaints include receiving bad information about loan statuses, delays or errors in re-amortizing payments after forbearance ended, and inaccurate reports of default or delinquency. Additionally, instances of alleged mismanagement, lack of transparency, or improper handling of personal data have also contributed to borrowers' difficulties in repayment.\""
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #3:\n",
        "\n",
        "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #3:\n",
        "\n",
        "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?\n",
        "\n",
        "#### âœ… Answer #3:\n",
        "\n",
        "1. In the above example we set the threshold to 20%. In FAQ-like sentences, a low % might not work well because many adjacent chunks may be too similar. So, the 1st method would be to try a higher 50th-75th percentile to detect topic shifts.\n",
        "2. Try a hybrid approach to switch to topic level.  \n",
        "        * sim(QA_i, QA_i+1) < percentile(sim_all_QA_pairs, threshold)\n",
        "3. If it is FAQs, We could pre-process the docs to treat pairs as a unit. e.g.\n",
        "        * chunks = [f\"Q: {q}\\nA: {a}\" for q, a in faq_pairs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against each other.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "825"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(loan_complaint_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\"\"\"\n",
        "Our data is: loan_complaint_data\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangSmith key and project to track latency and cost\n",
        "from uuid import uuid4\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Retrievers-eval-{uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test that tracing is working\n",
        "# OpenAI is emptying my bank account\n",
        "\"\"\"\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# This should now be traced in LangSmith\n",
        "test_llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
        "test_result = test_llm.invoke(\"Hello, testing LangSmith tracing\")\n",
        "print(\"LangSmith tracing enabled!\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ragas\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a90e9053d33e4a4da1232ebf3e87a2e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/539 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: Invalid json output: The borrowerâ€™s loan was in forbearance, but they unexpectedly received notice from Sloan Servicing that they were 90 days past due and owed over $9000, without being given a chance to cure the default. Their credit score dropped significantly after the servicer reported them to the credit bureau without prior contact. Attempts to request forbearance and an income-driven repayment plan were unsuccessful due to denial and website issues, so the borrower mailed the required forms with proof of income. The loan status online is unclear, and the borrower also experienced a breach of personal and financial data, violating FERPA. They are requesting full cancellation of their student debt.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "371b7d9ca9534c6e8573160c9fd038cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/825 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 80fb4b28-5494-4bd7-aff9-c92037e8d423 does not have a summary. Skipping filtering.\n",
            "Node fd7b6455-e499-4049-877c-c1739e835ac8 does not have a summary. Skipping filtering.\n",
            "Node bbd18c7b-b3eb-41be-89b8-9670ac2658dc does not have a summary. Skipping filtering.\n",
            "Node cbd3a9aa-c4af-477d-88ee-88791117824a does not have a summary. Skipping filtering.\n",
            "Node eafc86c8-351e-4a82-8159-d9da208ac12f does not have a summary. Skipping filtering.\n",
            "Node 023fa053-ace3-4d99-9daf-e3807ac5b4d8 does not have a summary. Skipping filtering.\n",
            "Node 8b078791-c28b-41b4-844b-0c2161e15047 does not have a summary. Skipping filtering.\n",
            "Node a3573a58-1f61-4a09-a6dd-cdb8ee0db360 does not have a summary. Skipping filtering.\n",
            "Node 619d2c79-90f0-4924-97a3-b00484e21c43 does not have a summary. Skipping filtering.\n",
            "Node 57c65ed4-8b53-4777-8425-1658a29865b3 does not have a summary. Skipping filtering.\n",
            "Node f5b7b882-02eb-4739-9334-1f356316ae1a does not have a summary. Skipping filtering.\n",
            "Node f8d422f7-ccb7-499c-859b-8a18eb9a0f79 does not have a summary. Skipping filtering.\n",
            "Node 21341be8-1dcf-4218-8a64-e90189e5c4dc does not have a summary. Skipping filtering.\n",
            "Node aefff858-70b3-401a-ad2b-f8191264a391 does not have a summary. Skipping filtering.\n",
            "Node f052196f-9b75-4953-98a0-4de2b4ec5c55 does not have a summary. Skipping filtering.\n",
            "Node b2444366-39ed-4ea2-aa0f-ae9a5142257a does not have a summary. Skipping filtering.\n",
            "Node 56a97a84-e47f-4973-8fa0-a4fbdfb23dd4 does not have a summary. Skipping filtering.\n",
            "Node b146781b-893b-4769-8dfb-9c432d62f5e7 does not have a summary. Skipping filtering.\n",
            "Node 1a0baed8-11ed-464f-af05-f68129b2bd2b does not have a summary. Skipping filtering.\n",
            "Node fe95086f-fdb1-4876-88da-ac6569912df5 does not have a summary. Skipping filtering.\n",
            "Node 1771d8bb-7e92-4a22-ab53-f67ef9badac8 does not have a summary. Skipping filtering.\n",
            "Node 50e72db2-1ec5-4b3a-8539-b422a001309c does not have a summary. Skipping filtering.\n",
            "Node 836c18b4-7cb2-4cf2-8106-4f693eada260 does not have a summary. Skipping filtering.\n",
            "Node 74a4258d-534c-4c2d-91ac-1932777b88b2 does not have a summary. Skipping filtering.\n",
            "Node c0f91ac0-5ded-45bf-b32c-8ddbfd5e3f03 does not have a summary. Skipping filtering.\n",
            "Node 577d5b2c-b3d3-4b33-b09e-4c16fceaf0bb does not have a summary. Skipping filtering.\n",
            "Node ed2b09c5-24e8-4d5b-95f9-3a6e9c370a07 does not have a summary. Skipping filtering.\n",
            "Node 2ddb9cfc-522b-438a-8375-161f259863d1 does not have a summary. Skipping filtering.\n",
            "Node 4fbbac13-c139-40b9-8831-9aefe59c31e4 does not have a summary. Skipping filtering.\n",
            "Node 3de2dbde-7ae3-41da-8e93-307136c0d4a7 does not have a summary. Skipping filtering.\n",
            "Node 27e54e63-dd3d-41f1-ae1b-c128adf1e5a3 does not have a summary. Skipping filtering.\n",
            "Node 2ed3233d-6e10-482e-99f1-7ee9f9cd6e22 does not have a summary. Skipping filtering.\n",
            "Node 0a0627eb-850d-4d48-9d47-36c5de8b7871 does not have a summary. Skipping filtering.\n",
            "Node 8144949d-5360-4eaf-a1ac-ed26e881ff07 does not have a summary. Skipping filtering.\n",
            "Node ba5ba99c-b8ab-4ea3-a760-e1f09e26fa01 does not have a summary. Skipping filtering.\n",
            "Node 6d770344-cdea-4d12-bf19-7b9a792d7fd7 does not have a summary. Skipping filtering.\n",
            "Node 1d25d811-f79e-4b11-8da7-a2754acdf7ba does not have a summary. Skipping filtering.\n",
            "Node 255cb50a-beb7-4460-8152-d7ca9795843c does not have a summary. Skipping filtering.\n",
            "Node 2345bf5c-dadd-4d30-b303-412c0569af1d does not have a summary. Skipping filtering.\n",
            "Node d910555f-5c88-4cbd-a3f3-773eaa785d7a does not have a summary. Skipping filtering.\n",
            "Node 84e8a41b-a1ec-4752-a007-551e21bd24a0 does not have a summary. Skipping filtering.\n",
            "Node 61e47ba7-a012-440e-89ca-6854a4e9012e does not have a summary. Skipping filtering.\n",
            "Node 856a3252-34be-4f87-8ec4-6d1efd0a59c0 does not have a summary. Skipping filtering.\n",
            "Node 65ccda15-b71e-415a-bec1-4e65502b8454 does not have a summary. Skipping filtering.\n",
            "Node 6bcde07b-e5c1-4762-bea8-71a33023961d does not have a summary. Skipping filtering.\n",
            "Node 0811e9c4-da94-40df-9910-ccf7c3d6a3db does not have a summary. Skipping filtering.\n",
            "Node cbff3f0a-4e08-4a4d-ad19-9c3b35b07db4 does not have a summary. Skipping filtering.\n",
            "Node 16afc3b1-402e-493f-ada3-ae630d7338d4 does not have a summary. Skipping filtering.\n",
            "Node ab020c37-e549-4faa-aa29-d51ccbb62c8d does not have a summary. Skipping filtering.\n",
            "Node bede5da9-bda2-41f3-9330-b9a56b5221ea does not have a summary. Skipping filtering.\n",
            "Node 98018321-7187-41a1-ad30-15f67c0d49cb does not have a summary. Skipping filtering.\n",
            "Node 7ed72a50-fc15-4ece-8adb-7e8bdecb5556 does not have a summary. Skipping filtering.\n",
            "Node 78ae68d9-4632-45ab-b968-53bb9b1ff686 does not have a summary. Skipping filtering.\n",
            "Node 1dcd64d7-9cfb-4ca0-b783-91b13819f3ac does not have a summary. Skipping filtering.\n",
            "Node feb9830c-5279-4a36-a80c-912ca9cb351d does not have a summary. Skipping filtering.\n",
            "Node 32cc5ecb-b726-4b09-af1e-da628e1ecba7 does not have a summary. Skipping filtering.\n",
            "Node 2addf300-4afd-4809-bb38-4eeab0809846 does not have a summary. Skipping filtering.\n",
            "Node cb1ead12-841a-4b9d-b31f-000ee466f9d7 does not have a summary. Skipping filtering.\n",
            "Node bf0b6738-e808-4976-88c4-91ecd86cbf61 does not have a summary. Skipping filtering.\n",
            "Node b7cc8043-6642-4695-9479-f2375fc7efd3 does not have a summary. Skipping filtering.\n",
            "Node d9bc4494-28f2-4eda-ad4c-843234e61caa does not have a summary. Skipping filtering.\n",
            "Node ed0e68e4-36a2-498d-963b-155ad738c73d does not have a summary. Skipping filtering.\n",
            "Node 96f8f8d1-d9ce-45eb-9f83-93f4d1562272 does not have a summary. Skipping filtering.\n",
            "Node facb4b02-3555-4a21-bd9a-4f2d7d323396 does not have a summary. Skipping filtering.\n",
            "Node 182a8efc-fcc3-46ff-a272-9003558dac36 does not have a summary. Skipping filtering.\n",
            "Node 7fea0baf-35f7-4896-a63e-36b0070a0ecd does not have a summary. Skipping filtering.\n",
            "Node bf83bc25-e77b-445e-a731-e7835138af6f does not have a summary. Skipping filtering.\n",
            "Node 16a1b366-22fb-4b9a-9c9e-1581af4a12cf does not have a summary. Skipping filtering.\n",
            "Node 0a8c098d-3795-4fe9-ba3e-e48581e6aa28 does not have a summary. Skipping filtering.\n",
            "Node 840aafd3-6417-4d9b-b5b3-ef11ddef3df6 does not have a summary. Skipping filtering.\n",
            "Node 70f90b87-a37c-4de8-8f0f-677def82796c does not have a summary. Skipping filtering.\n",
            "Node e7bcafa0-e65a-4699-84a6-2deb8477654a does not have a summary. Skipping filtering.\n",
            "Node dc2696e5-ffec-4670-8457-3fd88e8a69b8 does not have a summary. Skipping filtering.\n",
            "Node 5f8ec562-7edb-46ed-b0c8-8870c6bf0aa2 does not have a summary. Skipping filtering.\n",
            "Node 47969186-66ca-42f4-8cd0-403ab525a856 does not have a summary. Skipping filtering.\n",
            "Node ac0c3be4-1136-4790-97f9-26391a1a1fa9 does not have a summary. Skipping filtering.\n",
            "Node dd17ecf2-ba79-4a6c-8367-3c2d1848c14a does not have a summary. Skipping filtering.\n",
            "Node 0f8607ca-84a1-4ee1-8f01-0da003b6a7b6 does not have a summary. Skipping filtering.\n",
            "Node 6f40a561-2028-4324-a1ec-3fe054cc1808 does not have a summary. Skipping filtering.\n",
            "Node c525e1c2-fa62-4b21-b689-624a204d7cd2 does not have a summary. Skipping filtering.\n",
            "Node a250482d-61cb-48b8-87c4-a7398838ee8d does not have a summary. Skipping filtering.\n",
            "Node 52cc93d7-41af-4200-9744-46477e699c87 does not have a summary. Skipping filtering.\n",
            "Node 92a16454-ed95-41e1-b008-ad2421cd7f2f does not have a summary. Skipping filtering.\n",
            "Node b8dfc71e-d2aa-4cd6-bebd-2e0cb1cc0edc does not have a summary. Skipping filtering.\n",
            "Node ffefe1ad-aa9b-450d-ae1b-198d1aec9091 does not have a summary. Skipping filtering.\n",
            "Node 913eac4a-8aea-4ae3-9a76-d74de3605fdf does not have a summary. Skipping filtering.\n",
            "Node e8aed6e1-42d9-4931-99b3-56f77ceca059 does not have a summary. Skipping filtering.\n",
            "Node 25c297c1-5009-494c-805e-5bb215c5d749 does not have a summary. Skipping filtering.\n",
            "Node 756cbf5d-657b-4b6d-bad6-1a5d84ced1d2 does not have a summary. Skipping filtering.\n",
            "Node f7bfc493-c2ad-47e1-9a5a-ff33a30947d6 does not have a summary. Skipping filtering.\n",
            "Node 5c5d111a-f680-478a-a786-35bcc32adc03 does not have a summary. Skipping filtering.\n",
            "Node a5b1b7ee-80bb-47a9-a3b0-a7358dfe9eac does not have a summary. Skipping filtering.\n",
            "Node b931b173-e33b-4e92-8bae-0369a15985be does not have a summary. Skipping filtering.\n",
            "Node 7ad4baa1-1fe6-47eb-9fa5-7ff09d44aad6 does not have a summary. Skipping filtering.\n",
            "Node fb6cf824-e8d6-4992-ad08-bfb68e0278ba does not have a summary. Skipping filtering.\n",
            "Node 3651bc2a-f1b3-4623-bd84-dfeac88dae7d does not have a summary. Skipping filtering.\n",
            "Node 894ce92b-ce77-47be-892c-356e79db1cbc does not have a summary. Skipping filtering.\n",
            "Node 8c3d6175-b56c-4ddb-93d2-87473d21f1ca does not have a summary. Skipping filtering.\n",
            "Node 09adfe35-35ce-47ae-a40b-83727d8dadda does not have a summary. Skipping filtering.\n",
            "Node 6b908878-6e4e-482b-9a1d-e5147069da7a does not have a summary. Skipping filtering.\n",
            "Node e2f71af4-cd42-4424-b966-a09dc6aa6ea9 does not have a summary. Skipping filtering.\n",
            "Node ec3301f9-7958-4131-82f7-652b162ed96d does not have a summary. Skipping filtering.\n",
            "Node b500a73c-bed3-417c-ac0f-4713f16ea07f does not have a summary. Skipping filtering.\n",
            "Node 633ce4b7-883e-4ea5-8e33-f5e5b5ded191 does not have a summary. Skipping filtering.\n",
            "Node 2e9f73ec-9d10-4e2e-a5a0-3592b739e6cc does not have a summary. Skipping filtering.\n",
            "Node de5765bb-a060-4259-a927-a8d731237d8a does not have a summary. Skipping filtering.\n",
            "Node 88ce6b02-2d8a-4a48-915e-2d0bfcb59409 does not have a summary. Skipping filtering.\n",
            "Node e6ef0da1-f642-490e-8f6c-7a5018e167be does not have a summary. Skipping filtering.\n",
            "Node c9978c64-336d-4004-8564-85e3c8014956 does not have a summary. Skipping filtering.\n",
            "Node f27d1659-c48c-4cef-9bd0-abfbffd61bb8 does not have a summary. Skipping filtering.\n",
            "Node db72cbdd-463f-4bbb-b73f-41534e6e0e4b does not have a summary. Skipping filtering.\n",
            "Node 984fb4f4-e75b-4941-8091-dd73d7e54886 does not have a summary. Skipping filtering.\n",
            "Node c4f88b47-cf69-459a-916c-c092be5f0a3f does not have a summary. Skipping filtering.\n",
            "Node 4c2adbfa-836e-47a3-94db-ce670ad78dc7 does not have a summary. Skipping filtering.\n",
            "Node 29fa8bf2-4d01-4b54-bec8-b638124b51bb does not have a summary. Skipping filtering.\n",
            "Node 03d9f402-47e8-43bb-b385-c6bef13c3f8d does not have a summary. Skipping filtering.\n",
            "Node df1f08b4-cc2c-4485-9414-bb8be3758e12 does not have a summary. Skipping filtering.\n",
            "Node 1a410f75-0824-47db-ac43-98db7a427eeb does not have a summary. Skipping filtering.\n",
            "Node abe0205e-fe4c-46cc-8983-dccf93f40ca2 does not have a summary. Skipping filtering.\n",
            "Node 996d0dbb-2f8d-4b68-8668-7d0d1cfa419b does not have a summary. Skipping filtering.\n",
            "Node e06a7f77-880f-47af-af7c-508875c3a8f1 does not have a summary. Skipping filtering.\n",
            "Node f3a72718-1f06-41ec-b40e-81a4cb09454e does not have a summary. Skipping filtering.\n",
            "Node acea6787-fadc-4651-8727-860de9529058 does not have a summary. Skipping filtering.\n",
            "Node 2ff8c979-afad-4058-b6cd-823a61f35bf5 does not have a summary. Skipping filtering.\n",
            "Node 9bd19608-a5c5-4cd8-a52e-a98052d6e349 does not have a summary. Skipping filtering.\n",
            "Node 46c3faba-9d89-4e41-b999-0683e28a6291 does not have a summary. Skipping filtering.\n",
            "Node 27ee48e1-5267-45b7-af30-4f0412473f84 does not have a summary. Skipping filtering.\n",
            "Node 862e8575-ada9-4425-8a2d-b43391b21858 does not have a summary. Skipping filtering.\n",
            "Node 6cb6100c-36b4-4a33-a11e-f8d80c3df09f does not have a summary. Skipping filtering.\n",
            "Node c41ebf58-8838-4bc0-aa9a-8f21e9c43ad8 does not have a summary. Skipping filtering.\n",
            "Node 7498ff4b-7005-46e9-a98f-c958b87e7a41 does not have a summary. Skipping filtering.\n",
            "Node 00c4761b-8458-4363-8e63-43d4533defee does not have a summary. Skipping filtering.\n",
            "Node c34fd04b-8c18-4822-8afe-b7bb69d0f322 does not have a summary. Skipping filtering.\n",
            "Node 66857522-cbbd-4b65-8ac7-7fe17e0a4523 does not have a summary. Skipping filtering.\n",
            "Node f3c2c43d-51cd-4340-aac2-aedab5b25c7b does not have a summary. Skipping filtering.\n",
            "Node 89ba41db-0ca5-45cc-8d9b-a964ae973df8 does not have a summary. Skipping filtering.\n",
            "Node 6fee6052-41bf-4852-8492-eb50a6ecbbe2 does not have a summary. Skipping filtering.\n",
            "Node ff50dfe1-66c5-4c91-bca3-8fbd858b6bc3 does not have a summary. Skipping filtering.\n",
            "Node f0c421a3-3b9c-4a21-bb02-db787b2ec0a3 does not have a summary. Skipping filtering.\n",
            "Node b10df837-174b-42dc-8ea9-e2353d7b9f66 does not have a summary. Skipping filtering.\n",
            "Node 31232c2e-af00-4d23-af77-bccd413aef98 does not have a summary. Skipping filtering.\n",
            "Node 2d7291b3-8b80-497b-a0e3-e74e1abcf60e does not have a summary. Skipping filtering.\n",
            "Node 3e399440-b28e-4f98-9068-ce801992f2b8 does not have a summary. Skipping filtering.\n",
            "Node 6263945b-db38-4297-b686-12959569efdc does not have a summary. Skipping filtering.\n",
            "Node 230ca254-230e-43ea-9261-c0948404e148 does not have a summary. Skipping filtering.\n",
            "Node dfed677d-d0da-4309-8028-b6af0126df77 does not have a summary. Skipping filtering.\n",
            "Node 439274ca-3676-40dc-b0cf-25b3b2b809ab does not have a summary. Skipping filtering.\n",
            "Node 2ce1d286-fb28-41a8-863a-c0fc4288d3dd does not have a summary. Skipping filtering.\n",
            "Node ab912f07-460d-4c6f-b0e2-652ccecc77a8 does not have a summary. Skipping filtering.\n",
            "Node 3ca06396-40d5-4cbf-816c-df54a71d7093 does not have a summary. Skipping filtering.\n",
            "Node 31f71dc9-4647-4560-8e61-4c07b9d5a1a0 does not have a summary. Skipping filtering.\n",
            "Node 793f2462-c5d1-49d3-bed1-a712317eeefc does not have a summary. Skipping filtering.\n",
            "Node a1eabcdc-66bc-44bd-aa92-4ceadef9b1f2 does not have a summary. Skipping filtering.\n",
            "Node f078ef99-7c89-4d50-a884-5489feb709a7 does not have a summary. Skipping filtering.\n",
            "Node 02d6b647-28ae-48e3-9db0-651a60efb46e does not have a summary. Skipping filtering.\n",
            "Node baa4d104-f39d-4982-8834-d91e64d43143 does not have a summary. Skipping filtering.\n",
            "Node 20456d0e-675e-49f3-b906-fd983f099275 does not have a summary. Skipping filtering.\n",
            "Node e969d855-5009-429b-ae55-59403ccb1155 does not have a summary. Skipping filtering.\n",
            "Node 313204d6-a19b-48ef-aeae-da6139651269 does not have a summary. Skipping filtering.\n",
            "Node 62601824-59be-4f3e-8443-bda01d40cb2d does not have a summary. Skipping filtering.\n",
            "Node 42f29afb-879a-455e-8f47-78f51f4d373c does not have a summary. Skipping filtering.\n",
            "Node 956a01cb-41f2-4632-a0a4-10522ee1a743 does not have a summary. Skipping filtering.\n",
            "Node abcfad4d-0652-4ba6-a474-4e7d1a21d33b does not have a summary. Skipping filtering.\n",
            "Node 4003e2e4-2e47-4ecf-ae37-cf7d7573ee1d does not have a summary. Skipping filtering.\n",
            "Node 2433f9d9-417c-4627-9601-0a020adaa6ad does not have a summary. Skipping filtering.\n",
            "Node e8294cf5-eab5-4931-a7b2-34722b7e150e does not have a summary. Skipping filtering.\n",
            "Node 9af05dc3-bc45-450e-bd42-e9ebc01503dd does not have a summary. Skipping filtering.\n",
            "Node 4da7bed1-5d53-4233-b1f2-5f711407016e does not have a summary. Skipping filtering.\n",
            "Node 5ee5e9c8-e3e1-413d-b216-25db4a2f8a32 does not have a summary. Skipping filtering.\n",
            "Node 7f18b1db-6a5d-49f8-8b8f-de7af4ff32ff does not have a summary. Skipping filtering.\n",
            "Node 7b054d65-d511-4bce-b57f-a3c9280300a8 does not have a summary. Skipping filtering.\n",
            "Node 822dd03d-c2e5-43d2-9ea8-e5cee4be53c8 does not have a summary. Skipping filtering.\n",
            "Node 32758c34-fef9-4071-b482-a32bc29e508f does not have a summary. Skipping filtering.\n",
            "Node e523078a-0d2c-466a-a919-9faaa50fad59 does not have a summary. Skipping filtering.\n",
            "Node 0d680718-255e-40ad-a32d-6586d5e2d430 does not have a summary. Skipping filtering.\n",
            "Node f617e18f-2910-4e7f-b993-d02f4d280961 does not have a summary. Skipping filtering.\n",
            "Node 3596a543-e1a3-41d2-91b4-8e429c098515 does not have a summary. Skipping filtering.\n",
            "Node 6a26ec2e-8f9b-4606-b12c-a389212c2697 does not have a summary. Skipping filtering.\n",
            "Node 10e13138-008c-43be-b4b4-c11a81bcddf5 does not have a summary. Skipping filtering.\n",
            "Node 7d3132bd-6d82-40f9-abd1-8a4ef668f971 does not have a summary. Skipping filtering.\n",
            "Node 9921bade-980a-4bbf-9813-13045d07e22d does not have a summary. Skipping filtering.\n",
            "Node 04fa2fec-597e-43e4-9606-beb12dde9d5d does not have a summary. Skipping filtering.\n",
            "Node a41a5e17-2d12-496b-badf-7da142f640b5 does not have a summary. Skipping filtering.\n",
            "Node 79ec87a8-3679-4c26-b6cc-b8d09286491e does not have a summary. Skipping filtering.\n",
            "Node 815e331c-5e4d-413d-9f0f-62f475c88da6 does not have a summary. Skipping filtering.\n",
            "Node 87c7a900-4412-4e69-bfd5-6dd7b3b286d6 does not have a summary. Skipping filtering.\n",
            "Node 2a1c9860-73c6-4e63-b34e-b62c127499b5 does not have a summary. Skipping filtering.\n",
            "Node 2f5771b5-d34a-410d-9d8d-b644cadf260a does not have a summary. Skipping filtering.\n",
            "Node a60f0241-d67e-4e8b-9cf0-0b793e614eec does not have a summary. Skipping filtering.\n",
            "Node 147bf243-ace9-4186-a692-3b2e3724a7ab does not have a summary. Skipping filtering.\n",
            "Node 6e98c784-61a9-4e19-baa0-b6ab8fafe5bd does not have a summary. Skipping filtering.\n",
            "Node 79b0a558-2d1b-45b2-b36b-1de059a8cba8 does not have a summary. Skipping filtering.\n",
            "Node fd664ec9-6885-41fa-9cb9-a010352e1213 does not have a summary. Skipping filtering.\n",
            "Node 30eb456a-8d05-4fd2-9209-97641888c389 does not have a summary. Skipping filtering.\n",
            "Node a6f41cf6-aae3-4240-adda-496325050a56 does not have a summary. Skipping filtering.\n",
            "Node 0dab0401-a2f3-4136-afe5-610b1c6ca3c7 does not have a summary. Skipping filtering.\n",
            "Node a115aff0-dd25-42ec-8aa1-8f5aaa7115a1 does not have a summary. Skipping filtering.\n",
            "Node 15854168-b243-4cdf-893d-7ace5548b1e7 does not have a summary. Skipping filtering.\n",
            "Node 87399c16-85f9-404c-916a-226a419dfa3c does not have a summary. Skipping filtering.\n",
            "Node 1cf84624-3659-43db-8e0c-47b4c69d17e7 does not have a summary. Skipping filtering.\n",
            "Node b2f4ac0e-e109-498f-bb2f-7e66ba70edf5 does not have a summary. Skipping filtering.\n",
            "Node b5648ca0-9058-475e-b524-0cffdf4c8b6c does not have a summary. Skipping filtering.\n",
            "Node 75163f75-95a3-4c4c-addb-3c957023470b does not have a summary. Skipping filtering.\n",
            "Node 73465592-02e5-4a93-9d05-a211c5439724 does not have a summary. Skipping filtering.\n",
            "Node 8ff9f17a-418b-41e1-b1e4-4075a9fa1b63 does not have a summary. Skipping filtering.\n",
            "Node f22694f4-d4c0-4d69-9912-ca54d3a4b491 does not have a summary. Skipping filtering.\n",
            "Node 3628512c-e251-4e72-890a-f391c8135f5b does not have a summary. Skipping filtering.\n",
            "Node 905ac5f6-acf9-490f-8ec0-df5fc7c014f7 does not have a summary. Skipping filtering.\n",
            "Node aa5cfc4f-598d-4a61-8267-e9319aa10ebc does not have a summary. Skipping filtering.\n",
            "Node a53e1a50-7159-4c9b-b51e-07731cc186bf does not have a summary. Skipping filtering.\n",
            "Node 94135f37-1c40-4c20-929c-ece04c20e1a0 does not have a summary. Skipping filtering.\n",
            "Node d608d48d-9821-4d17-8945-a26348323cab does not have a summary. Skipping filtering.\n",
            "Node 2f97f052-1360-4400-99ae-dcc02656a620 does not have a summary. Skipping filtering.\n",
            "Node 5d1a89d7-329e-426f-bc49-e164b69b9b6d does not have a summary. Skipping filtering.\n",
            "Node 9f23f9b6-1da9-4ec4-b698-8be286091bd1 does not have a summary. Skipping filtering.\n",
            "Node 0fe458fe-a640-402a-b3e7-6e28346e2565 does not have a summary. Skipping filtering.\n",
            "Node a4eadc64-f287-4302-93c7-c9769dc85588 does not have a summary. Skipping filtering.\n",
            "Node 5b43132f-0855-4602-8a7e-2eb989ffd50a does not have a summary. Skipping filtering.\n",
            "Node 09eba520-3d7b-4baf-b5f0-969d0be01c84 does not have a summary. Skipping filtering.\n",
            "Node 24d9c901-9ba2-4ee5-bc9e-c22d2dff2134 does not have a summary. Skipping filtering.\n",
            "Node db774da2-118f-4593-bfae-13f9322a7de3 does not have a summary. Skipping filtering.\n",
            "Node a065552c-028b-4a1e-9ab6-7db70291083f does not have a summary. Skipping filtering.\n",
            "Node de1f112b-806a-4e18-b876-223858085716 does not have a summary. Skipping filtering.\n",
            "Node e7743352-c8e7-4673-9ee0-6766ff81a756 does not have a summary. Skipping filtering.\n",
            "Node cf6a27cf-358d-4faf-8fa2-4466e43b410d does not have a summary. Skipping filtering.\n",
            "Node 0a13aaa7-7054-4d80-9df2-e575f011a64c does not have a summary. Skipping filtering.\n",
            "Node 2c4f7b83-e8bd-413c-838c-f6f4aa5d8fd0 does not have a summary. Skipping filtering.\n",
            "Node 1ecec91b-f730-4312-a66a-b9ed1464ceda does not have a summary. Skipping filtering.\n",
            "Node c1a64200-3dc1-4ba5-a875-a0e97a3c066f does not have a summary. Skipping filtering.\n",
            "Node 93be6367-5d0b-4355-90dd-c7831e9d2c50 does not have a summary. Skipping filtering.\n",
            "Node f0f78e13-9fb7-4ec0-84b7-cf27c9bc7fdc does not have a summary. Skipping filtering.\n",
            "Node 41527921-5642-476a-9526-8f45101547a3 does not have a summary. Skipping filtering.\n",
            "Node b9ab78f3-b0b8-46d5-ab83-a3ae35acf7e0 does not have a summary. Skipping filtering.\n",
            "Node a8d37929-96e9-4cbe-817f-1be60bf44221 does not have a summary. Skipping filtering.\n",
            "Node c0f8fb9f-e938-4347-8a69-11aee11fca87 does not have a summary. Skipping filtering.\n",
            "Node 161630e5-2b73-468b-a0c9-def199a3b058 does not have a summary. Skipping filtering.\n",
            "Node 23d1569f-7a7c-4443-8ce4-7c7848b9aab3 does not have a summary. Skipping filtering.\n",
            "Node 78f34c22-aaad-476d-9cb9-08a26c7bc2d2 does not have a summary. Skipping filtering.\n",
            "Node cf0c9c66-f081-4098-81a2-474af6e95e0e does not have a summary. Skipping filtering.\n",
            "Node 5e2562f7-b001-4722-a85c-7d705e94ddfb does not have a summary. Skipping filtering.\n",
            "Node 5698db9c-c521-46b8-a6a0-8abda651a2be does not have a summary. Skipping filtering.\n",
            "Node b0df00f7-9bf5-4409-9057-8659fb0a32da does not have a summary. Skipping filtering.\n",
            "Node 74cab398-87da-4937-9427-0f32c826e4ae does not have a summary. Skipping filtering.\n",
            "Node e3e5b3af-7e84-4427-9c3c-ce1319947d53 does not have a summary. Skipping filtering.\n",
            "Node 618b7d89-9a4a-4ed9-a8d3-b769c486c5d6 does not have a summary. Skipping filtering.\n",
            "Node 0b02a34f-2d42-4226-8872-f74da70e0eef does not have a summary. Skipping filtering.\n",
            "Node 37d58cc1-d32b-4c8f-a4e3-ebcd768b890d does not have a summary. Skipping filtering.\n",
            "Node 6134e4e3-04ae-45db-99d6-277c9241c630 does not have a summary. Skipping filtering.\n",
            "Node b4fa533f-18b1-4321-9081-8b86efd43430 does not have a summary. Skipping filtering.\n",
            "Node a4382576-cf8b-47a0-a0ad-fcd9235abc39 does not have a summary. Skipping filtering.\n",
            "Node 783db9fb-1e5d-469e-8a39-2dc1a1ba1632 does not have a summary. Skipping filtering.\n",
            "Node 66f4573f-ccd2-4470-a16c-5e442d1fecb7 does not have a summary. Skipping filtering.\n",
            "Node c49e9d73-4572-4bf3-a652-a43967d5fce7 does not have a summary. Skipping filtering.\n",
            "Node b4d708ea-36f9-415d-8b0c-9a9d9bc41c8e does not have a summary. Skipping filtering.\n",
            "Node 0ffbf5b9-86f4-4f1a-ad94-06af0a2b4b30 does not have a summary. Skipping filtering.\n",
            "Node f22ac96d-8cd5-4b58-a617-5d735d37bd6c does not have a summary. Skipping filtering.\n",
            "Node 1fa32161-0d0b-45f5-92db-616898384363 does not have a summary. Skipping filtering.\n",
            "Node f1ecc2ee-9b36-4e9a-97bc-b533b50bbf7d does not have a summary. Skipping filtering.\n",
            "Node 7592276c-2ca3-4b68-93aa-60bec591de87 does not have a summary. Skipping filtering.\n",
            "Node 45337aaf-9cb8-410a-97d4-66d0bf7bd6eb does not have a summary. Skipping filtering.\n",
            "Node ea3a1267-da18-4d92-87cd-c869f9b2c1b2 does not have a summary. Skipping filtering.\n",
            "Node fcff5cb3-aad8-481f-8dc7-b4d955e2a168 does not have a summary. Skipping filtering.\n",
            "Node 810b2033-b2a8-436d-8310-d47bab390b79 does not have a summary. Skipping filtering.\n",
            "Node ea23f2d7-3e02-45f1-851e-1699f2f08843 does not have a summary. Skipping filtering.\n",
            "Node 3d69b25b-3dbb-4b7c-9263-cc563095bd22 does not have a summary. Skipping filtering.\n",
            "Node ef026725-177e-41b7-8122-7e48e9cc4b98 does not have a summary. Skipping filtering.\n",
            "Node e5251c45-7275-48b5-9a4f-e4741b67551d does not have a summary. Skipping filtering.\n",
            "Node a2753f3a-02a4-449f-aa01-0ca44bfaace1 does not have a summary. Skipping filtering.\n",
            "Node 12255726-a829-48a9-9f6b-f7715d93f0a2 does not have a summary. Skipping filtering.\n",
            "Node 2a7a0e95-2864-4938-a767-bf18f6b33f11 does not have a summary. Skipping filtering.\n",
            "Node 985bffa4-b77f-4c67-9a8f-7569689c8a53 does not have a summary. Skipping filtering.\n",
            "Node ec6ad105-5209-46a7-a730-082fa305b209 does not have a summary. Skipping filtering.\n",
            "Node 416e27c3-4380-480d-a92c-bfbd04bdefba does not have a summary. Skipping filtering.\n",
            "Node fa4f5be9-62c4-405b-bbc7-3bc7548e8b5d does not have a summary. Skipping filtering.\n",
            "Node 3e7daa3c-37d2-4627-997d-d811ea057d85 does not have a summary. Skipping filtering.\n",
            "Node 35e50693-1ab5-4546-a6c1-757cb4e5d98a does not have a summary. Skipping filtering.\n",
            "Node df3afaf0-0a87-4c6a-a914-c4809fabe74a does not have a summary. Skipping filtering.\n",
            "Node 655d76e8-14b0-4b8f-9e05-7205e620a7b1 does not have a summary. Skipping filtering.\n",
            "Node 69a9d5c6-71f7-464a-967f-30c47a76acfc does not have a summary. Skipping filtering.\n",
            "Node 715a98fc-7cf2-4299-b23f-39c976fb02d6 does not have a summary. Skipping filtering.\n",
            "Node f75fed1b-4ab2-49d5-88dc-c7aa054421ea does not have a summary. Skipping filtering.\n",
            "Node 180f5bf8-e806-405f-921d-37179c10e39d does not have a summary. Skipping filtering.\n",
            "Node bec1a53f-2821-40c0-aa8f-d1ea3bbf158c does not have a summary. Skipping filtering.\n",
            "Node d792926c-3e48-46a6-8523-7f1333b8f8d5 does not have a summary. Skipping filtering.\n",
            "Node 43540dec-e4a2-4c6d-bcc5-7786c41d4231 does not have a summary. Skipping filtering.\n",
            "Node b6aa3431-0d61-403e-8a8f-f4fa1b22b51e does not have a summary. Skipping filtering.\n",
            "Node f9643e8f-e9a2-4570-aec9-32b252df1171 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd7990d7d29a4061850b6070fd7f762c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/2189 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61df637edc2347bcb0413cfc6edfd48a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: Node fd664ec9-6885-41fa-9cb9-a010352e1213 has no summary_embedding\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57fc3b09f1c54a93bdac1b50dcba89b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7c286a4aeb14bb7a332728ceebe2b89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3eb3d4cdb6d24c7ea89a523de87efe44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(loan_complaint_data, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did Nelnet handle the re-amortization of f...</td>\n",
              "      <td>[The federal student loan COVID-19 forbearance...</td>\n",
              "      <td>Payments on federal student loans serviced by ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why they give me wrong payment on IDR/IBR plan...</td>\n",
              "      <td>[I submitted my annual Income-Driven Repayment...</td>\n",
              "      <td>Even though I submitted my annual IDR recertif...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cancl my studnt loan debt?</td>\n",
              "      <td>[My personal and financial data was compromise...</td>\n",
              "      <td>I request full cancellation of my student loan...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why studentaid.gov say nelnet my issuer but ne...</td>\n",
              "      <td>[According to Studentaid.gov, Im to get an ema...</td>\n",
              "      <td>Studentaid.gov says that your issuer is nelnet...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Why they say I in forbearance till 2040 but I ...</td>\n",
              "      <td>[Since the resumption of federal loan payments...</td>\n",
              "      <td>They told me I was in forbearance until 2040 b...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How did EdFinancial Services mishandle my stud...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTo Whom It May Concern, I am writi...</td>\n",
              "      <td>EdFinancial Services mishandled your student l...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How have miscommunications and errors involvin...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI am filing a complaint regarding ...</td>\n",
              "      <td>Miscommunications and errors involving Edfinan...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does the role of a federal student loan se...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nU.S. Department of Education\\nFede...</td>\n",
              "      <td>A federal student loan servicer like Navient i...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>why edfinancial keep messin up my loan and mak...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI contacted Edfinancial about my f...</td>\n",
              "      <td>edfinancial messed up by addin $12000.00 capit...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How has the involvement of the loan servicer a...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI am a veteran that is 100 % XXXX ...</td>\n",
              "      <td>The involvement of the loan servicer has signi...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0  How did Nelnet handle the re-amortization of f...   \n",
              "1  Why they give me wrong payment on IDR/IBR plan...   \n",
              "2                         cancl my studnt loan debt?   \n",
              "3  Why studentaid.gov say nelnet my issuer but ne...   \n",
              "4  Why they say I in forbearance till 2040 but I ...   \n",
              "5  How did EdFinancial Services mishandle my stud...   \n",
              "6  How have miscommunications and errors involvin...   \n",
              "7  How does the role of a federal student loan se...   \n",
              "8  why edfinancial keep messin up my loan and mak...   \n",
              "9  How has the involvement of the loan servicer a...   \n",
              "\n",
              "                                  reference_contexts  \\\n",
              "0  [The federal student loan COVID-19 forbearance...   \n",
              "1  [I submitted my annual Income-Driven Repayment...   \n",
              "2  [My personal and financial data was compromise...   \n",
              "3  [According to Studentaid.gov, Im to get an ema...   \n",
              "4  [Since the resumption of federal loan payments...   \n",
              "5  [<1-hop>\\n\\nTo Whom It May Concern, I am writi...   \n",
              "6  [<1-hop>\\n\\nI am filing a complaint regarding ...   \n",
              "7  [<1-hop>\\n\\nU.S. Department of Education\\nFede...   \n",
              "8  [<1-hop>\\n\\nI contacted Edfinancial about my f...   \n",
              "9  [<1-hop>\\n\\nI am a veteran that is 100 % XXXX ...   \n",
              "\n",
              "                                           reference  \\\n",
              "0  Payments on federal student loans serviced by ...   \n",
              "1  Even though I submitted my annual IDR recertif...   \n",
              "2  I request full cancellation of my student loan...   \n",
              "3  Studentaid.gov says that your issuer is nelnet...   \n",
              "4  They told me I was in forbearance until 2040 b...   \n",
              "5  EdFinancial Services mishandled your student l...   \n",
              "6  Miscommunications and errors involving Edfinan...   \n",
              "7  A federal student loan servicer like Navient i...   \n",
              "8  edfinancial messed up by addin $12000.00 capit...   \n",
              "9  The involvement of the loan servicer has signi...   \n",
              "\n",
              "                       synthesizer_name  \n",
              "0  single_hop_specifc_query_synthesizer  \n",
              "1  single_hop_specifc_query_synthesizer  \n",
              "2  single_hop_specifc_query_synthesizer  \n",
              "3  single_hop_specifc_query_synthesizer  \n",
              "4  single_hop_specifc_query_synthesizer  \n",
              "5  multi_hop_specific_query_synthesizer  \n",
              "6  multi_hop_specific_query_synthesizer  \n",
              "7  multi_hop_specific_query_synthesizer  \n",
              "8  multi_hop_specific_query_synthesizer  \n",
              "9  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ragas.testset.synthesizers.testset_schema.Testset"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)     # Show entire column text\n",
        "pd.set_option(\"display.max_columns\", None)      # Show all columns\n",
        "pd.set_option(\"display.max_rows\", 100)          # Adjust as needed\n",
        "pd.set_option(\"display.width\", 0)               # Let it wrap naturally\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mdataset\u001b[49m.to_pandas()\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[32m      4\u001b[39m html=(df.to_html(max_rows=\u001b[38;5;28;01mNone\u001b[39;00m, max_cols=\u001b[38;5;28;01mNone\u001b[39;00m))\n",
            "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "df = dataset.to_pandas()\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "html=(df.to_html(max_rows=None, max_cols=None))\n",
        "scroll_html = f\"\"\"\n",
        "<div style=\"height:400px; overflow:auto; border:1px solid #ccc\">\n",
        "{html}\n",
        "</div>\n",
        "\"\"\"\n",
        "display(HTML(scroll_html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "#   Converting df into ragasEvaluationDataset\n",
        "from ragas import EvaluationDataset\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selecting a judge model\n",
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total retrievers to evaluate: 7\n",
            "- naive_retriever\n",
            "- bm25_retriever\n",
            "- compression_retriever\n",
            "- multi_query_retriever\n",
            "- parent_document_retriever\n",
            "- ensemble_retriever\n",
            "- semantic_retriever\n"
          ]
        }
      ],
      "source": [
        "# Collect all retrievers in a dictionary \n",
        "retrievers_dict = {\n",
        "    \"naive_retriever\": naive_retriever,\n",
        "    \"bm25_retriever\": bm25_retriever, \n",
        "    \"compression_retriever\": compression_retriever,\n",
        "    \"multi_query_retriever\": multi_query_retriever,\n",
        "    \"parent_document_retriever\": parent_document_retriever,\n",
        "    \"ensemble_retriever\": ensemble_retriever,\n",
        "    \"semantic_retriever\": semantic_retriever\n",
        "}\n",
        "\n",
        "print(f\"Total retrievers to evaluate: {len(retrievers_dict)}\")\n",
        "for name in retrievers_dict.keys():\n",
        "    print(f\"- {name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_all_retrievers_to_dataset(dataframe, retrievers_dict, k=10):\n",
        "    \"\"\"\n",
        "    Add retrieved_contexts columns for ALL retrievers to a single dataset\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with columns like:\n",
        "        - user_input, reference, reference_contexts (original)\n",
        "        - retrieved_contexts_naive\n",
        "        - retrieved_contexts_bm25  \n",
        "        - retrieved_contexts_compression\n",
        "        - etc.\n",
        "    \"\"\"\n",
        "    df_wretriever_context = dataframe.copy()\n",
        "    \n",
        "    for retriever_name, retriever in retrievers_dict.items():\n",
        "        print(f\"Adding {retriever_name} results...\")\n",
        "        \n",
        "        retrieved_contexts_list = []\n",
        "        for i, row in df_wretriever_context.iterrows():\n",
        "            question = row['user_input']\n",
        "            try:\n",
        "                # Configure and run retriever\n",
        "                if hasattr(retriever, 'search_kwargs'):\n",
        "                    retriever.search_kwargs = {\"k\": k}\n",
        "                elif hasattr(retriever, 'k'):\n",
        "                    retriever.k = k\n",
        "                    \n",
        "                docs = retriever.invoke(question)\n",
        "                retrieved_contexts = [doc.page_content for doc in docs]\n",
        "                retrieved_contexts_list.append(retrieved_contexts)\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {retriever_name} on question {i}: {e}\")\n",
        "                retrieved_contexts_list.append([])\n",
        "        \n",
        "        # Add column for this retriever\n",
        "        df_wretriever_context[f'{retriever_name}_contexts'] = retrieved_contexts_list\n",
        "    \n",
        "    return df_wretriever_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_all_retrievers_context = add_all_retrievers_to_dataset(\u001b[43mdf\u001b[49m, retrievers_dict, k=\u001b[32m10\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df_all_retrievers_context = add_all_retrievers_to_dataset(df, retrievers_dict, k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_retriever_column_to_synth_df(retriever, retriever_name, dataframe, k=10):\n",
        "    \"\"\"\n",
        "    Evaluate a single retriever using the test dataset\n",
        "    \n",
        "    Args:\n",
        "        retriever: The retriever to evaluate\n",
        "        retriever_name: Name for identification\n",
        "        dataframe: Pandas dataframe of thesynthetic evaluation dataset\n",
        "        k: Number of documents to retrieve\n",
        "    \n",
        "    Returns:\n",
        "        EvaluationDataset with retrieved contexts populated\n",
        "    \"\"\"\n",
        "    print(f\"Evaluating {retriever_name}...\")\n",
        "    \n",
        "    # For each question in dataset, get retrieved contexts\n",
        "    retrieved_contexts_list = []\n",
        "    df = dataframe.copy()\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        question = row['user_input']\n",
        "        \n",
        "        try:\n",
        "            # Configure retriever to return k documents\n",
        "            if hasattr(retriever, 'search_kwargs'):\n",
        "                retriever.search_kwargs = {\"k\": k}\n",
        "            elif hasattr(retriever, 'k'):\n",
        "                retriever.k = k\n",
        "                \n",
        "            # Get retrieved documents\n",
        "            docs = retriever.invoke(question)\n",
        "            \n",
        "            # Extract just the text content\n",
        "            retrieved_contexts = [doc.page_content for doc in docs]\n",
        "            retrieved_contexts_list.append(retrieved_contexts)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving for question {i}: {e}\")\n",
        "            retrieved_contexts_list.append([])  # Empty list if error\n",
        "    \n",
        "    # Add retrieved contexts to dataframe\n",
        "    df[f'{retriever_name}_contexts'] = retrieved_contexts_list\n",
        "    \n",
        "    # Convert back to EvaluationDataset\n",
        "    retriever_dataset = EvaluationDataset.from_pandas(df)\n",
        "    \n",
        "    print(f\"âœ“ Completed evaluation for {retriever_name}\")\n",
        "    return evaluated_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate all retrievers\n",
        "retriever_results = {}\n",
        "\n",
        "for retriever_name, retriever in retrievers_dict.items():\n",
        "    try:\n",
        "        evaluated_dataset = add_retriever_column_to_synth_df(retriever, retriever_name, df, k=10)\n",
        "            retriever, \n",
        "            retriever_name, \n",
        "            evaluation_dataset, \n",
        "            k=10\n",
        "        )\n",
        "        retriever_results[retriever_name] = evaluated_dataset\n",
        "        print(f\"Successfully evaluated {retriever_name}\\n\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Failed to evaluate {retriever_name}: {e}\\n\")\n",
        "        continue\n",
        "\n",
        "print(f\"Successfully evaluated {len(retriever_results)} out of {len(retrievers_dict)} retrievers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import ragas metrics for retrieval evaluation\n",
        "from ragas.metrics import context_precision, context_recall\n",
        "\n",
        "# Metrics to use for retrieval evaluation  \n",
        "retrieval_metrics = [context_precision, context_recall]\n",
        "\n",
        "print(\"Available metrics for retrieval evaluation:\")\n",
        "for metric in retrieval_metrics:\n",
        "    print(f\"- {metric.name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.metrics import LLMContextRecall, context_precision, context_recall, ContextEntityRecall\n",
        "from ragas import evaluate, RunConfig\n",
        "\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), ContextEntityRecall(),context_precision, context_recall],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "==========================================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset type: <class 'ragas.testset.synthesizers.testset_schema.Testset'>\n",
            "Dataset length: 10\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dataset type: {type(dataset)}\")\n",
        "print(f\"Dataset length: {len(dataset) if hasattr(dataset, '__len__') else 'No length'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name']\n",
            "Number of rows: 10\n"
          ]
        }
      ],
      "source": [
        "if hasattr(dataset, 'to_pandas'):\n",
        "    df = dataset.to_pandas()\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "    print(f\"Number of rows: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First item structure:\n",
            "Has user_input: True\n",
            "Has reference: True\n",
            "Has reference_contexts: True\n"
          ]
        }
      ],
      "source": [
        "if len(dataset) > 0:\n",
        "    print(\"First item structure:\")\n",
        "    print(f\"Has user_input: {'user_input' in df.columns}\")\n",
        "    print(f\"Has reference: {'reference' in df.columns}\")  \n",
        "    print(f\"Has reference_contexts: {'reference_contexts' in df.columns}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
